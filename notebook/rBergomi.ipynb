{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "774adfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from simulator import rBergomi\n",
    "from deep_hedge import dnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e750597",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "grid_num = 30\n",
    "path_num = 10000\n",
    "T = 30./365.\n",
    "H = 0.1\n",
    "eta = 1.9\n",
    "xi = 0.235*0.235\n",
    "rho = -0.7\n",
    "S0 = 100.\n",
    "K = 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e91051b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "S, V = rBergomi.get_path(seed, grid_num, path_num, T, S0, H, eta, xi, rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f5c3e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "MC_price = np.average(np.maximum(S[-1] - K, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1b2d040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.013439648833331"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MC_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea28c7f8-dcc8-4fe6-b8fa-e031827408a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dS = S[1:] - S[:-1]\n",
    "dV = V[1:] - V[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c87f1cbf-6df8-432e-b602-4e8a40d88f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_network = dnn.FeedForwardNetwork(input_size=2, output_size=1, hidden_size=100)\n",
    "z_network = dnn.FeedForwardNetwork(input_size=2, output_size=2, hidden_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "142b0b4e-78f9-4730-9408-80d2ca5cadc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 9 time: 29 Training critic loss: 3.93597937e+00 Training actor loss: 3.83796835e+00\n",
      "ep: 19 time: 29 Training critic loss: 4.06941414e+00 Training actor loss: 4.01097250e+00\n",
      "ep: 29 time: 29 Training critic loss: 2.82034540e+00 Training actor loss: 2.85649014e+00\n",
      "ep: 39 time: 29 Training critic loss: 2.54890656e+00 Training actor loss: 2.57082486e+00\n",
      "ep: 49 time: 29 Training critic loss: 2.41235328e+00 Training actor loss: 2.41900492e+00\n",
      "ep: 59 time: 29 Training critic loss: 2.29462624e+00 Training actor loss: 2.29046059e+00\n",
      "ep: 69 time: 29 Training critic loss: 2.21148109e+00 Training actor loss: 2.20773602e+00\n",
      "ep: 79 time: 29 Training critic loss: 2.19302177e+00 Training actor loss: 2.18981290e+00\n",
      "ep: 89 time: 29 Training critic loss: 2.19599175e+00 Training actor loss: 2.19370937e+00\n",
      "ep: 99 time: 29 Training critic loss: 2.18041301e+00 Training actor loss: 2.17865086e+00\n",
      "ep: 109 time: 29 Training critic loss: 2.15960741e+00 Training actor loss: 2.15867901e+00\n",
      "ep: 119 time: 29 Training critic loss: 2.15401220e+00 Training actor loss: 2.15360856e+00\n",
      "ep: 129 time: 29 Training critic loss: 2.14355826e+00 Training actor loss: 2.14358234e+00\n",
      "ep: 139 time: 29 Training critic loss: 2.13218975e+00 Training actor loss: 2.13239002e+00\n",
      "ep: 149 time: 29 Training critic loss: 2.12450576e+00 Training actor loss: 2.12457418e+00\n",
      "ep: 159 time: 29 Training critic loss: 2.11537957e+00 Training actor loss: 2.11538363e+00\n",
      "ep: 169 time: 29 Training critic loss: 2.10652113e+00 Training actor loss: 2.10645962e+00\n",
      "ep: 179 time: 29 Training critic loss: 2.09788895e+00 Training actor loss: 2.09787893e+00\n",
      "ep: 189 time: 29 Training critic loss: 2.08963466e+00 Training actor loss: 2.08966303e+00\n",
      "ep: 199 time: 29 Training critic loss: 2.08028507e+00 Training actor loss: 2.08027148e+00\n",
      "ep: 209 time: 29 Training critic loss: 2.07202935e+00 Training actor loss: 2.07202697e+00\n",
      "ep: 219 time: 29 Training critic loss: 2.06433153e+00 Training actor loss: 2.06434178e+00\n",
      "ep: 229 time: 29 Training critic loss: 2.05656338e+00 Training actor loss: 2.05655909e+00\n",
      "ep: 239 time: 29 Training critic loss: 2.04679275e+00 Training actor loss: 2.04679489e+00\n",
      "ep: 249 time: 29 Training critic loss: 2.04116631e+00 Training actor loss: 2.04117131e+00\n",
      "ep: 259 time: 29 Training critic loss: 2.03583670e+00 Training actor loss: 2.03583717e+00\n",
      "ep: 269 time: 29 Training critic loss: 2.03012800e+00 Training actor loss: 2.03013015e+00\n",
      "ep: 279 time: 29 Training critic loss: 2.02697253e+00 Training actor loss: 2.02697587e+00\n",
      "ep: 289 time: 29 Training critic loss: 2.02303171e+00 Training actor loss: 2.02303338e+00\n",
      "ep: 299 time: 29 Training critic loss: 2.02195024e+00 Training actor loss: 2.02195048e+00\n",
      "ep: 309 time: 29 Training critic loss: 2.02827764e+00 Training actor loss: 2.02827764e+00\n",
      "ep: 319 time: 29 Training critic loss: 2.01984882e+00 Training actor loss: 2.01984930e+00\n",
      "ep: 329 time: 29 Training critic loss: 2.01872706e+00 Training actor loss: 2.01872706e+00\n",
      "ep: 339 time: 29 Training critic loss: 2.01751566e+00 Training actor loss: 2.01751590e+00\n",
      "ep: 349 time: 29 Training critic loss: 2.01618171e+00 Training actor loss: 2.01618171e+00\n",
      "ep: 359 time: 29 Training critic loss: 2.01483941e+00 Training actor loss: 2.01483965e+00\n",
      "ep: 369 time: 29 Training critic loss: 2.01372838e+00 Training actor loss: 2.01372862e+00\n",
      "ep: 379 time: 29 Training critic loss: 2.01240778e+00 Training actor loss: 2.01240730e+00\n",
      "ep: 389 time: 29 Training critic loss: 2.00976396e+00 Training actor loss: 2.00976396e+00\n",
      "ep: 399 time: 29 Training critic loss: 2.00804234e+00 Training actor loss: 2.00804257e+00\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "opt_y = optim.Adam(params=y_network.parameters(), lr=learning_rate)\n",
    "opt_z = optim.Adam(params=z_network.parameters(), lr=learning_rate)\n",
    "\n",
    "scheduler_y = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_y, 'min', factor=0.5, patience=500, min_lr=1e-7, verbose=True)\n",
    "scheduler_z = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_z, 'min', factor=0.5, patience=500, min_lr=1e-7, verbose=True)\n",
    "\n",
    "for ep in range(400):\n",
    "    states = np.array([[S[0][i], V[0][i]] for i in range(path_num)])\n",
    "    y = y_network(torch.FloatTensor(states))\n",
    "    p = torch.squeeze(y)\n",
    "    targets = torch.FloatTensor(np.maximum(S[-1] - K, 0))\n",
    "    for t in range(grid_num):\n",
    "        states = np.array([[S[t][i], V[t][i]] for i in range(path_num)])\n",
    "        z = z_network(torch.FloatTensor(states))\n",
    "        p = p + z[:,0] * torch.FloatTensor(dS[t]) + z[:,1] * torch.FloatTensor(dV[t])\n",
    "            \n",
    "    if ep%2==0:\n",
    "        critic_loss = torch.nn.MSELoss()(p, targets)\n",
    "        opt_y.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        opt_y.step()\n",
    "    else:\n",
    "        actor_loss = torch.nn.MSELoss()(p, targets)\n",
    "        opt_z.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        opt_z.step()\n",
    "        \n",
    "    if ep % 10 == 9:\n",
    "        scheduler_y.step(critic_loss)\n",
    "        scheduler_z.step(actor_loss)\n",
    "        print('ep: {}'.format(ep),\n",
    "              'time: {}'.format(t),\n",
    "              'Training critic loss: {:.8e}'.format(critic_loss.data.numpy()),\n",
    "              'Training actor loss: {:.8e}'.format(actor_loss.data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "456ca00f-a63a-4212-be0a-28a37d6830d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.2338, 2.2338, 2.2338,  ..., 2.2338, 2.2338, 2.2338],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "states = np.array([[S[0][i], V[0][i]] for i in range(path_num)])\n",
    "y = y_network(torch.FloatTensor(states))\n",
    "print(y[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a761c5c5-e96f-44fe-8b61-66a16eef5b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_network = dnn.FeedForwardNetwork(input_size=2, output_size=3, hidden_size=100)\n",
    "z_network = dnn.FeedForwardNetwork(input_size=4, output_size=2, hidden_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fde0337e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 9 time: 29 Training critic loss: 1.07903862e+01 Training actor loss: 1.08887835e+01\n",
      "ep: 19 time: 29 Training critic loss: 3.43784952e+00 Training actor loss: 3.48486567e+00\n",
      "ep: 29 time: 29 Training critic loss: 2.30514455e+00 Training actor loss: 2.30508709e+00\n",
      "ep: 39 time: 29 Training critic loss: 2.36897540e+00 Training actor loss: 2.34845376e+00\n",
      "ep: 49 time: 29 Training critic loss: 2.40398884e+00 Training actor loss: 2.38689804e+00\n",
      "ep: 59 time: 29 Training critic loss: 2.32226443e+00 Training actor loss: 2.31199169e+00\n",
      "ep: 69 time: 29 Training critic loss: 2.22488093e+00 Training actor loss: 2.22086310e+00\n",
      "ep: 79 time: 29 Training critic loss: 2.18199444e+00 Training actor loss: 2.17992640e+00\n",
      "ep: 89 time: 29 Training critic loss: 2.17379260e+00 Training actor loss: 2.17331505e+00\n",
      "ep: 99 time: 29 Training critic loss: 2.16418481e+00 Training actor loss: 2.16365671e+00\n",
      "ep: 109 time: 29 Training critic loss: 2.14014077e+00 Training actor loss: 2.13985324e+00\n",
      "ep: 119 time: 29 Training critic loss: 2.12571073e+00 Training actor loss: 2.12530637e+00\n",
      "ep: 129 time: 29 Training critic loss: 2.11343741e+00 Training actor loss: 2.11321449e+00\n",
      "ep: 139 time: 29 Training critic loss: 2.09768581e+00 Training actor loss: 2.09751463e+00\n",
      "ep: 149 time: 29 Training critic loss: 2.08534646e+00 Training actor loss: 2.08530474e+00\n",
      "ep: 159 time: 29 Training critic loss: 2.07153010e+00 Training actor loss: 2.07156372e+00\n",
      "ep: 169 time: 29 Training critic loss: 2.05821013e+00 Training actor loss: 2.05821800e+00\n",
      "ep: 179 time: 29 Training critic loss: 2.04628229e+00 Training actor loss: 2.04630661e+00\n",
      "ep: 189 time: 29 Training critic loss: 2.03552842e+00 Training actor loss: 2.03549170e+00\n",
      "ep: 199 time: 29 Training critic loss: 2.02513552e+00 Training actor loss: 2.02511811e+00\n",
      "ep: 209 time: 29 Training critic loss: 2.01596594e+00 Training actor loss: 2.01595926e+00\n",
      "ep: 219 time: 29 Training critic loss: 2.00833559e+00 Training actor loss: 2.00832915e+00\n",
      "ep: 229 time: 29 Training critic loss: 2.00083232e+00 Training actor loss: 2.00083470e+00\n",
      "ep: 239 time: 29 Training critic loss: 1.99516034e+00 Training actor loss: 1.99516010e+00\n",
      "ep: 249 time: 29 Training critic loss: 1.99094868e+00 Training actor loss: 1.99094820e+00\n",
      "ep: 259 time: 29 Training critic loss: 1.98744881e+00 Training actor loss: 1.98745155e+00\n",
      "ep: 269 time: 29 Training critic loss: 1.98489320e+00 Training actor loss: 1.98489177e+00\n",
      "ep: 279 time: 29 Training critic loss: 1.98267865e+00 Training actor loss: 1.98267365e+00\n",
      "ep: 289 time: 29 Training critic loss: 1.98056948e+00 Training actor loss: 1.98056483e+00\n",
      "ep: 299 time: 29 Training critic loss: 1.97854507e+00 Training actor loss: 1.97854078e+00\n",
      "ep: 309 time: 29 Training critic loss: 1.97629917e+00 Training actor loss: 1.97629535e+00\n",
      "ep: 319 time: 29 Training critic loss: 1.97407496e+00 Training actor loss: 1.97407067e+00\n",
      "ep: 329 time: 29 Training critic loss: 1.97198594e+00 Training actor loss: 1.97198462e+00\n",
      "ep: 339 time: 29 Training critic loss: 1.97381032e+00 Training actor loss: 1.97380543e+00\n",
      "ep: 349 time: 29 Training critic loss: 1.96759379e+00 Training actor loss: 1.96759224e+00\n",
      "ep: 359 time: 29 Training critic loss: 1.96522319e+00 Training actor loss: 1.96522069e+00\n",
      "ep: 369 time: 29 Training critic loss: 1.96272361e+00 Training actor loss: 1.96271741e+00\n",
      "ep: 379 time: 29 Training critic loss: 1.95954859e+00 Training actor loss: 1.95954180e+00\n",
      "ep: 389 time: 29 Training critic loss: 1.95599294e+00 Training actor loss: 1.95598555e+00\n",
      "ep: 399 time: 29 Training critic loss: 1.95306051e+00 Training actor loss: 1.95305037e+00\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "opt_y = optim.Adam(params=y_network.parameters(), lr=learning_rate)\n",
    "opt_z = optim.Adam(params=z_network.parameters(), lr=learning_rate)\n",
    "\n",
    "scheduler_y = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_y, 'min', factor=0.5, patience=500, min_lr=1e-7, verbose=True)\n",
    "scheduler_z = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_z, 'min', factor=0.5, patience=500, min_lr=1e-7, verbose=True)\n",
    "\n",
    "for ep in range(400):\n",
    "    states = np.array([[S[0][i], V[0][i]] for i in range(path_num)])\n",
    "    y = y_network(torch.FloatTensor(states))\n",
    "    p = y[:,0]\n",
    "    targets = torch.FloatTensor(np.maximum(S[-1] - K, 0))\n",
    "    for t in range(grid_num):\n",
    "        states = np.array([[S[t][i], V[t][i]] for i in range(path_num)])\n",
    "        if t == 0:\n",
    "            states = torch.cat((torch.FloatTensor(states), y[:, 1:]), 1)\n",
    "        else:\n",
    "            states = torch.cat((torch.FloatTensor(states), z), 1)\n",
    "        z = z_network(states)\n",
    "        p = p + z[:,0] * torch.FloatTensor(dS[t]) + z[:,1] * torch.FloatTensor(dV[t])\n",
    "            \n",
    "    if ep%2==0:\n",
    "        critic_loss = torch.nn.MSELoss()(p, targets)\n",
    "        opt_y.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        opt_y.step()\n",
    "    else:\n",
    "        actor_loss = torch.nn.MSELoss()(p, targets)\n",
    "        opt_z.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        opt_z.step()\n",
    "        \n",
    "    if ep % 10 == 9:\n",
    "        scheduler_y.step(critic_loss)\n",
    "        scheduler_z.step(actor_loss)\n",
    "        print('ep: {}'.format(ep),\n",
    "              'time: {}'.format(t),\n",
    "              'Training critic loss: {:.8e}'.format(critic_loss.data.numpy()),\n",
    "              'Training actor loss: {:.8e}'.format(actor_loss.data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c07a35e-1bfc-4901-b96c-d76a22bdad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = np.array([[S[0][i], V[0][i]] for i in range(path_num)])\n",
    "y = y_network(torch.FloatTensor(states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f0dcf56-83c5-41bc-8804-6ce56bb4ef9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.2296, 2.2296, 2.2296,  ..., 2.2296, 2.2296, 2.2296],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f20dcdc7-0615-42d1-84a0-f1a4d039e0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_network = dnn.FeedForwardNetwork(input_size=2, output_size=3, hidden_size=100)\n",
    "z_network = dnn.FeedForwardNetwork(input_size=4, output_size=4, hidden_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8a30061-42eb-4f83-a7ba-db67e6a4c596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 9 time: 29 Training critic loss: 1.25398092e+01 Training actor loss: 1.24094105e+01\n",
      "ep: 19 time: 29 Training critic loss: 4.81526852e+00 Training actor loss: 4.76439667e+00\n",
      "ep: 29 time: 29 Training critic loss: 2.26286530e+00 Training actor loss: 2.26988316e+00\n",
      "ep: 39 time: 29 Training critic loss: 2.71872020e+00 Training actor loss: 2.73342609e+00\n",
      "ep: 49 time: 29 Training critic loss: 2.77288103e+00 Training actor loss: 2.78337812e+00\n",
      "ep: 59 time: 29 Training critic loss: 2.43854141e+00 Training actor loss: 2.44344091e+00\n",
      "ep: 69 time: 29 Training critic loss: 2.23457503e+00 Training actor loss: 2.23569679e+00\n",
      "ep: 79 time: 29 Training critic loss: 2.23852372e+00 Training actor loss: 2.23717427e+00\n",
      "ep: 89 time: 29 Training critic loss: 2.24491549e+00 Training actor loss: 2.24310231e+00\n",
      "ep: 99 time: 29 Training critic loss: 2.22562504e+00 Training actor loss: 2.22481155e+00\n",
      "ep: 109 time: 29 Training critic loss: 2.21270752e+00 Training actor loss: 2.21282220e+00\n",
      "ep: 119 time: 29 Training critic loss: 2.20175838e+00 Training actor loss: 2.20193601e+00\n",
      "ep: 129 time: 29 Training critic loss: 2.19107294e+00 Training actor loss: 2.19078469e+00\n",
      "ep: 139 time: 29 Training critic loss: 2.18163800e+00 Training actor loss: 2.18159461e+00\n",
      "ep: 149 time: 29 Training critic loss: 2.17255306e+00 Training actor loss: 2.17242694e+00\n",
      "ep: 159 time: 29 Training critic loss: 2.16348505e+00 Training actor loss: 2.16333008e+00\n",
      "ep: 169 time: 29 Training critic loss: 2.15422320e+00 Training actor loss: 2.15406418e+00\n",
      "ep: 179 time: 29 Training critic loss: 2.14467454e+00 Training actor loss: 2.14452505e+00\n",
      "ep: 189 time: 29 Training critic loss: 2.13465810e+00 Training actor loss: 2.13449979e+00\n",
      "ep: 199 time: 29 Training critic loss: 2.12433696e+00 Training actor loss: 2.12449813e+00\n",
      "ep: 209 time: 29 Training critic loss: 2.11361480e+00 Training actor loss: 2.11369038e+00\n",
      "ep: 219 time: 29 Training critic loss: 2.10230637e+00 Training actor loss: 2.10209274e+00\n",
      "ep: 229 time: 29 Training critic loss: 2.08981252e+00 Training actor loss: 2.08981323e+00\n",
      "ep: 239 time: 29 Training critic loss: 2.07716489e+00 Training actor loss: 2.07713914e+00\n",
      "ep: 249 time: 29 Training critic loss: 2.06398749e+00 Training actor loss: 2.06399441e+00\n",
      "ep: 259 time: 29 Training critic loss: 2.04871535e+00 Training actor loss: 2.04871106e+00\n",
      "ep: 269 time: 29 Training critic loss: 2.02853155e+00 Training actor loss: 2.02852178e+00\n",
      "ep: 279 time: 29 Training critic loss: 2.01194191e+00 Training actor loss: 2.01191688e+00\n",
      "ep: 289 time: 29 Training critic loss: 2.00694656e+00 Training actor loss: 2.00690866e+00\n",
      "ep: 299 time: 29 Training critic loss: 1.99258828e+00 Training actor loss: 1.99256587e+00\n",
      "ep: 309 time: 29 Training critic loss: 1.98077261e+00 Training actor loss: 1.98077321e+00\n",
      "ep: 319 time: 29 Training critic loss: 1.97842109e+00 Training actor loss: 1.97844183e+00\n",
      "ep: 329 time: 29 Training critic loss: 1.97412133e+00 Training actor loss: 1.97412574e+00\n",
      "ep: 339 time: 29 Training critic loss: 1.97100413e+00 Training actor loss: 1.97100568e+00\n",
      "ep: 349 time: 29 Training critic loss: 1.96777928e+00 Training actor loss: 1.96777928e+00\n",
      "ep: 359 time: 29 Training critic loss: 1.96437299e+00 Training actor loss: 1.96436679e+00\n",
      "ep: 369 time: 29 Training critic loss: 1.96016967e+00 Training actor loss: 1.96016562e+00\n",
      "ep: 379 time: 29 Training critic loss: 1.97158551e+00 Training actor loss: 1.97158754e+00\n",
      "ep: 389 time: 29 Training critic loss: 1.97537327e+00 Training actor loss: 1.97537696e+00\n",
      "ep: 399 time: 29 Training critic loss: 1.95046055e+00 Training actor loss: 1.95045447e+00\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "opt_y = optim.Adam(params=y_network.parameters(), lr=learning_rate)\n",
    "opt_z = optim.Adam(params=z_network.parameters(), lr=learning_rate)\n",
    "\n",
    "scheduler_y = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_y, 'min', factor=0.5, patience=500, min_lr=1e-7, verbose=True)\n",
    "scheduler_z = torch.optim.lr_scheduler.ReduceLROnPlateau(opt_z, 'min', factor=0.5, patience=500, min_lr=1e-7, verbose=True)\n",
    "\n",
    "for ep in range(400):\n",
    "    states = np.array([[S[0][i], V[0][i]] for i in range(path_num)])\n",
    "    y = y_network(torch.FloatTensor(states))\n",
    "    p = y[:,0]\n",
    "    targets = torch.FloatTensor(np.maximum(S[-1] - K, 0))\n",
    "    for t in range(grid_num):\n",
    "        states = np.array([[S[t][i], V[t][i]] for i in range(path_num)])\n",
    "        if t == 0:\n",
    "            states = torch.cat((torch.FloatTensor(states), y[:, 1:]), 1)\n",
    "        else:\n",
    "            states = torch.cat((torch.FloatTensor(states), z[:, 2:]), 1)\n",
    "        z = z_network(states)\n",
    "        p = p + z[:,0] * torch.FloatTensor(dS[t]) + z[:,1] * torch.FloatTensor(dV[t])\n",
    "            \n",
    "    if ep%2==0:\n",
    "        critic_loss = torch.nn.MSELoss()(p, targets)\n",
    "        opt_y.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        opt_y.step()\n",
    "    else:\n",
    "        actor_loss = torch.nn.MSELoss()(p, targets)\n",
    "        opt_z.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        opt_z.step()\n",
    "        \n",
    "    if ep % 10 == 9:\n",
    "        scheduler_y.step(critic_loss)\n",
    "        scheduler_z.step(actor_loss)\n",
    "        print('ep: {}'.format(ep),\n",
    "              'time: {}'.format(t),\n",
    "              'Training critic loss: {:.8e}'.format(critic_loss.data.numpy()),\n",
    "              'Training actor loss: {:.8e}'.format(actor_loss.data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7807f87e-641b-4147-a39f-ff9ca0049c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.2322, 2.2322, 2.2322,  ..., 2.2322, 2.2322, 2.2322],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "states = np.array([[S[0][i], V[0][i]] for i in range(path_num)])\n",
    "y = y_network(torch.FloatTensor(states))\n",
    "print(y[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a80e3f48-ce19-470b-b28c-a291ebe34816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.2322,  6.7361, -3.7967],\n",
       "        [ 2.2322,  6.7361, -3.7967],\n",
       "        [ 2.2322,  6.7361, -3.7967],\n",
       "        ...,\n",
       "        [ 2.2322,  6.7361, -3.7967],\n",
       "        [ 2.2322,  6.7361, -3.7967],\n",
       "        [ 2.2322,  6.7361, -3.7967]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412a2e3b-5323-44e2-b8d2-56a5a47aa08e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
